{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a11c0d3-f379-496d-abbe-9007524c4607",
   "metadata": {},
   "source": [
    "# Graphical Lasso Demonstration\n",
    "This notebook performs the Graphical Lasso on a 4‑dimensional Gaussian random vector whose precision matrix corresponds to the $4$-dimensional graph with two cliques $\\{1,2,3\\}$ and $\\{2 , 3 , 4\\}$. The estimation is performed using:\n",
    "\n",
    "1. **`graphical_lasso()`** from `sklearn.covariance`\n",
    "2. A **custom implementation** solved using the **BFGS algorithm** from `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27426075-eb1a-4fd8-b5b1-ba5297ac292f",
   "metadata": {},
   "source": [
    "## 1. Define the graph and precision matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bf8723-ec41-4302-af3e-1dc0c527ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = 4\n",
    "Theta = np.array([\n",
    "    [10,  5,  3, 0],\n",
    "    [ 5, 10,  5,  3],\n",
    "    [ 3,  5, 10 ,   5],\n",
    "    [ 0,  3,  5, 10]\n",
    "])\n",
    "Sigma = np.linalg.inv(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee47caa-f5b1-4333-ab39-c0827e7baffb",
   "metadata": {},
   "source": [
    "## 2. Simulate Gaussian sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0efbba68-bea8-429c-a31a-a4140fa984e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08481423, -0.14148212,  0.50104707, -0.13408804],\n",
       "       [ 0.01500972, -0.09995599, -0.31503787, -0.05363327],\n",
       "       [-0.79674774,  0.70858684,  0.41542281, -0.16985076],\n",
       "       [ 0.13601284, -0.27093846, -0.09018928,  0.27965782],\n",
       "       [-0.19631773,  0.10019048,  0.36549836, -0.25742948]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(7)\n",
    "N = 10**4\n",
    "mean = np.zeros(d)\n",
    "X = np.random.multivariate_normal(mean, Sigma, size=N)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68c85f71-11b8-418d-a436-d9a320f5b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14357317, -0.06813447, -0.02699007,  0.03311031],\n",
       "       [-0.06813447,  0.16791951, -0.0507427 , -0.02354432],\n",
       "       [-0.02699007, -0.0507427 ,  0.16574231, -0.06764802],\n",
       "       [ 0.03311031, -0.02354432, -0.06764802,  0.13810744]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EstimSigma = np.cov(X, rowvar=False)\n",
    "EstimSigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e15f7c-c820-4c9a-b413-7eb7f1ebc5c3",
   "metadata": {},
   "source": [
    "## 3. Graphical Lasso Using `sklearn.covariance.graphical_lasso`\n",
    "The `graphical_lasso()` function solves the penalized likelihood problem\n",
    "\n",
    "$$\n",
    "argmax_\\Theta \\; \\log\\det(\\Theta) - \\operatorname{tr}(S\\Theta) - \\lambda \\|\\Theta\\|_1\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **S** is the sample covariance matrix\n",
    "- **λ** controls the sparsity of the solution\n",
    "- The algorithm used is the **GLasso algorithm** from Friedman et al. (2008, *Biostatistics*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e78ee02-193e-44d2-ace9-b54cee1a790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision matrix (Theta):\n",
      " [[ 9.89783259  4.95307758  3.12110398 -0.        ]\n",
      " [ 4.95307758  9.89543835  5.03547702  2.95954525]\n",
      " [ 3.12110398  5.03547702 10.14766418  5.07332757]\n",
      " [-0.          2.95954525  5.07332757 10.22565074]]\n",
      "Covariance matrix (Sigma):\n",
      " [[ 0.14357317 -0.06805475 -0.02691088  0.03304815]\n",
      " [-0.06805475  0.16791951 -0.05066255 -0.02346429]\n",
      " [-0.02691088 -0.05066255  0.16574231 -0.06756802]\n",
      " [ 0.03304815 -0.02346429 -0.06756802  0.13810744]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import  graphical_lasso\n",
    "\n",
    "covariance , precision = graphical_lasso(EstimSigma , alpha=  8* pow(10 , -5))\n",
    "\n",
    "print(\"Precision matrix (Theta):\\n\", precision)\n",
    "print(\"Covariance matrix (Sigma):\\n\", covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08725a-7a0f-4b80-991e-81698a0f26fa",
   "metadata": {},
   "source": [
    "## 4. Graphical Lasso Using a Custom Optimization Function\n",
    "We now solve the **same optimization problem** using the **BFGS** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f485950-028c-45a9-b6c1-c9a023264eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.89345975e+00,  4.94841315e+00,  3.11731406e+00,\n",
       "        -5.66208864e-05],\n",
       "       [ 4.94841315e+00,  9.88944458e+00,  5.02944184e+00,\n",
       "         2.95596227e+00],\n",
       "       [ 3.11731406e+00,  5.02944184e+00,  1.01419062e+01,\n",
       "         5.06913419e+00],\n",
       "       [-5.66208864e-05,  2.95596227e+00,  5.06913419e+00,\n",
       "         1.02218998e+01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "### Helper: Build a Symmetric Matrix from a Vector\n",
    "def construct_symmetric_matrix(theta_vec):\n",
    "    Theta_mat = np.zeros((d, d))\n",
    "    idx = np.triu_indices(d)\n",
    "    Theta_mat[idx] = theta_vec\n",
    "    Theta_mat = Theta_mat + Theta_mat.T - np.diag(np.diag(Theta_mat))\n",
    "    return Theta_mat\n",
    "\n",
    "### Penalized Log-Likelihood\n",
    "def penalized_log_likelihood(theta_vec, S , lamb):\n",
    "    Theta_mat = construct_symmetric_matrix(theta_vec)\n",
    "    det = np.linalg.det(Theta_mat)\n",
    "    if det <= 0:\n",
    "        return -np.inf\n",
    "    sum_Theta = np.absolute(Theta_mat).sum()    \n",
    "    return np.log(det) - np.trace(S @ Theta_mat )  - lamb * sum_Theta + lamb * np.absolute(np.diag(Theta_mat)).sum()\n",
    "\n",
    "\n",
    "### Initial Matrix\n",
    "A = np.random.randn(d, d)\n",
    "Theta0 = A @ A.T + d * np.eye(d)\n",
    "theta0_vec = Theta0[np.triu_indices(d)]\n",
    "\n",
    "\n",
    "lamb = pow(10 , -4)\n",
    "\n",
    "### Optimization via BFGS\n",
    "\n",
    "res = minimize(lambda t: -penalized_log_likelihood(t, EstimSigma , lamb),\n",
    "               theta0_vec, \n",
    "               method = \"BFGS\"\n",
    "              )\n",
    "\n",
    "Theta_MLE = construct_symmetric_matrix(res.x)\n",
    "Theta_MLE  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
