{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8685d2b",
   "metadata": {},
   "source": [
    "# Gaussian Graphical Model on a 4â€‘Cycle\n",
    "In this notebook we study a 4-dimensional Gaussian graphical model whose \n",
    "precision matrix corresponds to the **cycle graph**:\n",
    "\n",
    "$$\n",
    "1 \\;-\\; 2 \\;-\\; 3 \\;-\\; 4 \\;-\\; 1.\n",
    "$$\n",
    "\n",
    "Zeros in the **precision matrix** encode conditional independences.  \n",
    "We will:\n",
    "\n",
    "1. Define the precision matrix $ \\Theta $\n",
    "2. Compute the covariance matrix $ \\Sigma = \\Theta^{-1} $\n",
    "3. Simulate a sample $X_1,\\dots,X_N \\sim \\mathcal{N}(0, \\Sigma)$\n",
    "4. Standardize the margins to variance 1\n",
    "5. Estimate covariance and precision matrices from data\n",
    "6. Compute the maximum-likelihood estimate (MLE) of the precision matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abaf61",
   "metadata": {},
   "source": [
    "## 1. Define the graph and precision matrix\n",
    "Consider the following precision matrix \n",
    "\n",
    "$$\n",
    "\\Theta =\n",
    "\\begin{pmatrix}\n",
    "10 & 5 & 0 & 3 \\\\\n",
    "5 & 10 & 5 & 0 \\\\\n",
    "0 & 5 & 10 & 5 \\\\\n",
    "3 & 0 & 5 & 10\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We define the matrix $\\Sigma$ as the inverse of $\\Theta$, that is, $\\Sigma = \\Theta^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efbb1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29411765, -0.26470588,  0.23529412, -0.20588235],\n",
       "       [-0.26470588,  0.38823529, -0.31176471,  0.23529412],\n",
       "       [ 0.23529412, -0.31176471,  0.38823529, -0.26470588],\n",
       "       [-0.20588235,  0.23529412, -0.26470588,  0.29411765]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = 4\n",
    "Theta = np.array([\n",
    "    [10,  5,  0,  3],\n",
    "    [ 5, 10,  5,  0],\n",
    "    [ 0,  5, 10,  5],\n",
    "    [ 3,  0,  5, 10]\n",
    "])\n",
    "Sigma = np.linalg.inv(Theta)\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ea673",
   "metadata": {},
   "source": [
    "## 2. Simulate Gaussian sample\n",
    "We simulate a large sample from a centered multivariate normal distribution with covariance matrix $\\Sigma$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac849ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62154872, -0.71801739,  0.17602042, -0.16783284],\n",
       "       [ 0.54163047, -0.4116966 ,  0.96618277, -0.69574101],\n",
       "       [ 0.00518286, -0.14638079,  0.30370709, -0.29053133],\n",
       "       [-0.11780136,  0.03063679,  0.60636705, -0.36270261],\n",
       "       [ 0.09513002, -0.29269288,  0.06902821,  0.4848796 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10**6\n",
    "mean = np.zeros(d)\n",
    "X = np.random.multivariate_normal(mean, Sigma, size=N)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f45a49",
   "metadata": {},
   "source": [
    "## 3. Standardize margins\n",
    "We standardize the margins to variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71b51fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9981154 , 0.99722568, 0.99894653, 0.99900666])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.sqrt(np.diag(Sigma))\n",
    "X = X / std\n",
    "np.var(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fd920",
   "metadata": {},
   "source": [
    "## 4. Estimate covariance and precision\n",
    "We compute the MLE covariance matrix $$\n",
    "S = \\frac{1}{n} \\sum_{i =1}^n X_i^t X_i\n",
    "$$\n",
    "from our sample and then invert it to get an estimate of the precision matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a6ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the MLE for the covariance matrix:\n",
      " [[ 0.9981154  -0.78086859  0.69396025 -0.69857465]\n",
      " [-0.78086859  0.99722568 -0.80036266  0.69399612]\n",
      " [ 0.69396025 -0.80036266  0.99894653 -0.78150351]\n",
      " [-0.69857465  0.69399612 -0.78150351  0.99900666]]\n",
      "This is the estimate of the precision matrix computed as the inverse of the MLE covariance matrix:\n",
      " [[ 2.94102317e+00  1.68903859e+00  2.90553067e-03  8.85488298e-01]\n",
      " [ 1.68903859e+00  3.87621230e+00  1.93214679e+00 -1.77406274e-04]\n",
      " [ 2.90553067e-03  1.93214679e+00  3.86238541e+00  1.68126521e+00]\n",
      " [ 8.85488298e-01 -1.77406274e-04  1.68126521e+00  2.93553345e+00]]\n"
     ]
    }
   ],
   "source": [
    "EstimSigma = np.cov(X, rowvar=False)\n",
    "MLE_EstimSigma = ((N-1)/N) * EstimSigma\n",
    "EstimTheta = np.linalg.inv(MLE_EstimSigma)\n",
    "print(\"This is the MLE for the covariance matrix:\\n\"  , MLE_EstimSigma)\n",
    "print(\"This is the estimate of the precision matrix computed as the inverse of the MLE covariance matrix:\\n\"  , EstimTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecaa2a",
   "metadata": {},
   "source": [
    "## 5. Maximum-likelihood estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d16098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the MLE for the precision matrix :\n",
      " [[ 2.94102548e+00  1.68903111e+00  2.92474787e-03  8.85516879e-01]\n",
      " [ 1.68903111e+00  3.87617846e+00  1.93216640e+00 -1.41448029e-04]\n",
      " [ 2.92474787e-03  1.93216640e+00  3.86237952e+00  1.68124247e+00]\n",
      " [ 8.85516879e-01 -1.41448029e-04  1.68124247e+00  2.93549596e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20254817\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:596: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n",
      "C:\\Users\\20254817\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:596: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def construct_symmetric_matrix(theta_vec):\n",
    "    Theta_mat = np.zeros((d, d))\n",
    "    idx = np.triu_indices(d)\n",
    "    Theta_mat[idx] = theta_vec\n",
    "    Theta_mat = Theta_mat + Theta_mat.T - np.diag(np.diag(Theta_mat))\n",
    "    return Theta_mat\n",
    "\n",
    "def log_likelihood(theta_vec, S):\n",
    "    Theta_mat = construct_symmetric_matrix(theta_vec)\n",
    "    det = np.linalg.det(Theta_mat)\n",
    "    if det <= 0:\n",
    "        return -np.inf\n",
    "    return np.log(det) - np.trace(S @ Theta_mat)\n",
    "\n",
    "A = np.random.randn(d, d)\n",
    "Theta0 = A @ A.T + d * np.eye(d)\n",
    "theta0_vec = Theta0[np.triu_indices(d)]\n",
    "\n",
    "res = minimize(lambda t: -log_likelihood(t, EstimSigma),\n",
    "               theta0_vec)\n",
    "\n",
    "Theta_MLE = construct_symmetric_matrix(res.x)\n",
    "print(\"This is the MLE for the precision matrix :\\n\"  , Theta_MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704468c-778d-46e6-a879-76cca8d0bb09",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "-We simulated a Gaussian vector consistent with a given graph structure.\n",
    "\n",
    "-The precision matrix was initially estimated by inverting the MLE for the covariance matrix.\n",
    "\n",
    "-We then computed the MLE of the precision matrix by maximizing the log-likelihood (equivalently, minimizing the negative log-likelihood).\n",
    "\n",
    "-Both methods yielded the same results, confirming that the MLE for the precision matrix coincides with the inverse of the sample covariance matrix.\n",
    "\n",
    "-However, neither method identified exact zeros for $\\theta_{13}$ \n",
    " and $\\theta_{24}$\n",
    " . Introducing a lasso penalization with an appropriate regularization term could address this limitation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
