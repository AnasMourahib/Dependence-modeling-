{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a11c0d3-f379-496d-abbe-9007524c4607",
   "metadata": {},
   "source": [
    "# Graphical Lasso Demonstration\n",
    "This notebook performs the Graphical Lasso on a 4‑dimensional Gaussian random vector whose precision matrix corresponds to the $4$-dimensional graph with two cliques $\\{1,2,3\\}$ and $\\{2 , 3 , 4\\}$. The estimation is performed using:\n",
    "\n",
    "1. **`graphical_lasso()`** from `sklearn.covariance`\n",
    "2. A **custom implementation** solved using the **BFGS algorithm** from `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27426075-eb1a-4fd8-b5b1-ba5297ac292f",
   "metadata": {},
   "source": [
    "## 1. Define the graph and precision matrix\n",
    "\n",
    "We first define the precision matrix \n",
    "$$\n",
    "\\Theta =\n",
    "\\begin{pmatrix}\n",
    "10 & 5 & 3 & 0 \\\\\n",
    "5 & 10 & 5 & 3 \\\\\n",
    "3 & 5 & 10 & 5 \\\\\n",
    "0 & 3 & 5 & 10\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We define the inverse $\\Sigma= \\Theta^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bf8723-ec41-4302-af3e-1dc0c527ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = 4\n",
    "Theta = np.array([\n",
    "    [10,  5,  3, 0],\n",
    "    [ 5, 10,  5,  3],\n",
    "    [ 3,  5, 10 ,   5],\n",
    "    [ 0,  3,  5, 10]\n",
    "])\n",
    "Sigma = np.linalg.inv(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee47caa-f5b1-4333-ab39-c0827e7baffb",
   "metadata": {},
   "source": [
    "## 2. Simulate Gaussian sample\n",
    "\n",
    "We simulate form a centered Gaussian distribution with covariance matrix $\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efbba68-bea8-429c-a31a-a4140fa984e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0249882 ,  0.40326314, -0.33943285, -0.00079558],\n",
       "       [-0.32807514,  0.66074409, -0.15315525, -0.14403168],\n",
       "       [-0.49390619,  0.07857231, -0.2781498 ,  0.543012  ],\n",
       "       [ 0.23711111, -0.01183191, -0.05047926, -0.37161609],\n",
       "       [ 0.36719285, -0.06415889, -0.00331654, -0.16394107]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(7)\n",
    "N = 10**4\n",
    "mean = np.zeros(d)\n",
    "X = np.random.multivariate_normal(mean, Sigma, size=N)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c85f71-11b8-418d-a436-d9a320f5b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the sample covariance matrix computed from the sample:\n",
      " [[ 0.14063144 -0.06848973 -0.02245653  0.02948985]\n",
      " [-0.06848973  0.16717006 -0.05238776 -0.02333097]\n",
      " [-0.02245653 -0.05238776  0.16912751 -0.0706653 ]\n",
      " [ 0.02948985 -0.02333097 -0.0706653   0.14138246]]\n"
     ]
    }
   ],
   "source": [
    "EstimSigma = np.cov(X, rowvar=False)\n",
    "print(\"This is the sample covariance matrix computed from the sample:\\n\", EstimSigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e15f7c-c820-4c9a-b413-7eb7f1ebc5c3",
   "metadata": {},
   "source": [
    "## 3. Graphical Lasso Using `sklearn.covariance.graphical_lasso`\n",
    "The `graphical_lasso()` function solves the penalized likelihood problem\n",
    "$$\n",
    "argmax_\\Theta \\; \\log\\det(\\Theta) - \\operatorname{tr}(S\\Theta) - \\lambda \\|\\Theta\\|_1\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **S** is the sample covariance matrix\n",
    "- **λ** controls the sparsity of the solution\n",
    "- The algorithm used is the **GLasso algorithm** from Friedman et al. (2008, *Biostatistics*)\n",
    "\n",
    "\n",
    "As a penalization term, we fix $\\lambda = 10^{-4}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e78ee02-193e-44d2-ace9-b54cee1a790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Precision Matrix (Theta) using the glasso package:\n",
      " [[ 9.99241135  5.04961626  2.97528855  0.22335392]\n",
      " [ 5.04961626 10.07758961  5.09381078  3.14134341]\n",
      " [ 2.97528855  5.09381078 10.06653888  5.23853998]\n",
      " [ 0.22335392  3.14134341  5.23853998 10.15703503]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import  graphical_lasso\n",
    "\n",
    "covariance , precision = graphical_lasso(EstimSigma , alpha=   pow(10 , -4))\n",
    "\n",
    "print(\"Estimated Precision Matrix (Theta) using the glasso package:\\n\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08725a-7a0f-4b80-991e-81698a0f26fa",
   "metadata": {},
   "source": [
    "## 4. Graphical Lasso using an implementation of the LASSO-loglikelihood function \n",
    "We implement the Lasso log-Likelihood function given by \n",
    "\n",
    "$$\n",
    "L(\\Theta) =  \\log \\det(\\Theta) - trace (S \\cdot \\Theta) -\\lambda \\| \\Theta \\|_1,\n",
    "$$\n",
    "where $\\| \\Theta \\|_1$ is the sum of the absolute value of the entries from the precision matrix $\\Theta$ and $S$ is MLE covariance matrix, that is:\n",
    "$$\n",
    "S = \\frac{1}{n} \\sum_{i =1}^n X_i^t X_i\n",
    "$$\n",
    "\n",
    "We minimize the Lasso-loglikelihood function using the function **minimize()** with the **Broyden–Fletcher–Goldfarb–Shanno algorithm** method and we randomly choose initial values for the first step of the minimization. We get the estimate $\\hat{\\Theta}_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e04771-7cbb-428c-8a3c-24cb12aece2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Precision Matrix (Theta) using implemented LASSO log-likelihood function:\n",
      " [[ 9.99154076  5.04895117  2.97518607  0.22361391]\n",
      " [ 5.04895117 10.07699086  5.09371132  3.14156692]\n",
      " [ 2.97518607  5.09371132 10.06682585  5.23895107]\n",
      " [ 0.22361391  3.14156692  5.23895107 10.1575178 ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "### Helper: Build a Symmetric Matrix from a Vector\n",
    "def construct_symmetric_matrix(theta_vec):\n",
    "    Theta_mat = np.zeros((d, d))\n",
    "    idx = np.triu_indices(d)\n",
    "    Theta_mat[idx] = theta_vec\n",
    "    Theta_mat = Theta_mat + Theta_mat.T - np.diag(np.diag(Theta_mat))\n",
    "    return Theta_mat\n",
    "\n",
    "### Penalized Log-Likelihood\n",
    "def penalized_log_likelihood(theta_vec, S , lamb):\n",
    "    Theta_mat = construct_symmetric_matrix(theta_vec)\n",
    "    det = np.linalg.det(Theta_mat)\n",
    "    if det <= 0:\n",
    "        return -np.inf\n",
    "    sum_Theta = np.absolute(Theta_mat).sum()    \n",
    "    return np.log(det) - np.trace(S @ Theta_mat )  - lamb * sum_Theta + lamb * np.absolute(np.diag(Theta_mat)).sum()\n",
    "\n",
    "\n",
    "### Initial Matrix\n",
    "A = np.random.randn(d, d)\n",
    "Theta0 = A @ A.T + d * np.eye(d)\n",
    "theta0_vec = Theta0[np.triu_indices(d)]\n",
    "\n",
    "\n",
    "lamb = pow(10 , -4)\n",
    "\n",
    "### Optimization via BFGS\n",
    "\n",
    "res = minimize(lambda t: -penalized_log_likelihood(t, EstimSigma , lamb),\n",
    "               theta0_vec, \n",
    "               method = \"BFGS\"\n",
    "              )\n",
    "\n",
    "Theta_MLE = construct_symmetric_matrix(res.x)\n",
    "print(\"Estimated Precision Matrix (Theta) using implemented LASSO log-likelihood function:\\n\" , Theta_MLE)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40391304-f800-42c6-8d43-98864f8f4406",
   "metadata": {},
   "source": [
    "Note that both methods give the same results. Both estimations give good estimation for the precision matrix $\\Theta$, howveer both of them fail to detect $\\Theta_{14}=0$. One reason could be a bad choice for the penalization parameter $\\lambda$. There exists some known method to choose this penalization parameter: cross validation, AIC, BIC, etc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
